BRW_increase_rate          : 5.0
DSH_loss_m                 : 24.0
GED_threshold              : 10
MAX_BRW                    : 2.0
batchsize                  : 10
beam_width                 : 15
binary_regularizer_weight  : 5.0
clip                       : True
code_mse_w                 : 1.0
csm_GED_threshold          : 10
csm_batch_size             : 128
csm_beam_width             : 15
csm_coarsening             : None
csm_dataset                : AIDS700nef
csm_dataset_super_large    : False
csm_dataset_train          : aids700nef
csm_dataset_val_test       : aids700nef
csm_dropout                : 0.0
csm_ds_algo                : astar
csm_ds_kernel              : exp
csm_ds_metric              : ged
csm_ds_norm                : True
csm_gpu                    : 3
csm_graph_loss             : None
csm_ground_truth_file      : GT10.txt
csm_iters                  : 15
csm_iters_val_every        : 200
csm_iters_val_start        : 1400
csm_lambda_mse_loss        : 1.0
csm_laplacian              : gcn
csm_layer_num              : 17
csm_learning_rate          : 0.001
csm_max_nodes              : 10
csm_model                  : siamese_regression
csm_model_name             : Our Model
csm_need_gc                : False
csm_node_embs_norm         : False
csm_node_feat_encoder      : onehot
csm_node_feat_name         : type
csm_node_label_name        : label
csm_num_glabels            : 2
csm_ordering               : bfs
csm_plot_max_num           : 10
csm_plot_results           : True
csm_pred_sim_dist          : sim
csm_random_walk            : None
csm_real_pair_bs           : 64
csm_scale                  : 0.7
csm_special_note           : scale exp
csm_supersource            : False
csm_supply_sim_dist        : sim
csm_train_fake_from        : None
csm_train_fake_gen         : None
csm_train_real_percent     : 1.0
csm_valid_percentage       : 0.25
csm_weight_decay           : 0.0
dataset                    : AIDS700nef
dropout                    : 0.0
early_stopping             : 50
emb_mse_w                  : 10.0
embedding_dim              : 256
epochs                     : 5
fine_grained               : True
ground_truth_file          : GT10.txt
hamming_dist_thres         : 2
hash_code_len              : 32
hidden1                    : 256
hidden2                    : 128
hidden3                    : 64
hidden4                    : 348
hidden5                    : 256
hidden6                    : 128
k                          : 0
l1_loss_w                  : 0.0
label_type                 : ged
laplacian                  : gcn
last_n                     : 5
layer_1                    : CSM_GraphConvolution:output_dim=128,dropout=False,bias=True,act=relu,sparse_inputs=True,type=gcn
layer_2                    : CSM_GraphConvolution:input_dim=128,output_dim=64,dropout=False,bias=True,act=relu,sparse_inputs=False,type=gcn
layer_3                    : CSM_GraphConvolution:input_dim=64,output_dim=32,dropout=False,bias=True,act=identity,sparse_inputs=False,type=gcn
layer_4                    : CSM_GraphConvolutionCollector:gcn_num=3,fix_size=50,mode=0,padding_value=0,align_corners=True,perturb=None
layer_5                    : CSM_CNN:start_cnn=True,end_cnn=False,window_size=100,kernel_stride=1,in_channel=1,out_channel=16,padding=SAME,pool_size=3,dropout=False,act=relu,bias=True,mode=separate,gcn_num=3
layer_6                    : CSM_CNN:start_cnn=False,end_cnn=False,window_size=25,kernel_stride=1,in_channel=16,out_channel=16,padding=SAME,pool_size=3,dropout=False,act=relu,bias=True,mode=separate,gcn_num=3
layer_7                    : CSM_CNN:start_cnn=False,end_cnn=False,window_size=10,kernel_stride=1,in_channel=16,out_channel=32,padding=SAME,pool_size=3,dropout=False,act=relu,bias=True,mode=separate,gcn_num=3
layer_8                    : CSM_CNN:start_cnn=False,end_cnn=False,window_size=4,kernel_stride=1,in_channel=32,out_channel=64,padding=SAME,pool_size=3,dropout=False,act=relu,bias=True,mode=separate,gcn_num=3
layer_9                    : CSM_CNN:start_cnn=False,end_cnn=True,window_size=2,kernel_stride=1,in_channel=64,out_channel=128,padding=SAME,pool_size=2,dropout=False,act=relu,bias=True,mode=separate,gcn_num=3
layer_10                   : CSM_Dense:input_dim=384,output_dim=256,dropout=False,act=relu,bias=True
layer_11                   : CSM_Dense:input_dim=256,output_dim=128,dropout=False,act=relu,bias=True
layer_12                   : CSM_Dense:input_dim=128,output_dim=64,dropout=False,act=relu,bias=True
layer_13                   : CSM_Dense:input_dim=64,output_dim=32,dropout=False,act=relu,bias=True
layer_14                   : CSM_Dense:input_dim=32,output_dim=16,dropout=False,act=relu,bias=True
layer_15                   : CSM_Dense:input_dim=16,output_dim=8,dropout=False,act=relu,bias=True
layer_16                   : CSM_Dense:input_dim=8,output_dim=4,dropout=False,act=relu,bias=True
layer_17                   : CSM_Dense:input_dim=4,output_dim=1,dropout=False,act=identity,bias=True
learning_rate              : 0.001
max_degree                 : 3
node_feat_encoder          : onehot
node_feat_name             : type
node_label_name            : label
real_data_loss_weight      : 1.0
syn_data_loss_weight       : 1.0
top_k                      : 10
valid_percentage           : 0.0
weight_decay               : 0.0
ts                         : 2019-08-22T15:46:17.774347